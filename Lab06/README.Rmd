---
title: "Lab 06"
author: "Carmen Chen"
date: "10/1/2021"
output: github_document
always_allow_html: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "http://cran.rstudio.com")) 
library(tidyverse)
library(tidytext)
library(tibble)
library(dplyr)
```

##Download the data
```{r get-data, cache=TRUE}
fn <- "mtsamples.csv"
if(!file.exists(fn))
  download.file("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv", destfile = fn)

mtsamples <- read.csv(fn) #read data from a data frame
mtsamples <- as_tibble(mtsamples)
```


#Question 1: What specialties do we have?
We can use count() from dplyr to figure out how many different catagories do we have? Are these catagories related? overlapping? evenly distributed?


```{r dist-of-specialities}
specialties <- mtsamples %>%
  count(medical_specialty)

specialties %>%
  arrange(desc(n)) %>%
  top_n(15) %>%
  knitr::kable()
```

There are `r nrow(specialties)` specialties. Let's take a look at the distribution:

```{r dist1}
#Method 1 (not that pretty)
ggplot(mtsamples, aes(x = medical_specialty)) +
  geom_histogram(stat = "count") +
  coord_flip() #for better reading the categories
```

```{r dist2}
#Method 2
ggplot(specialties, aes(x = n, y = fct_reorder(medical_specialty, n))) + #x is frequency, y is the label, sorting the medical_specialty according to n
  geom_col() #plot column
```

These are not evenly distributed.


#Question 2
Tokenize the the words in the transcription column
Count the number of times each token appears
Visualize the top 20 most frequent words

```{r token-transcript}
mtsamples %>%
  unnest_tokens(output = word, input = transcription) %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(word, n))) +
  geom_col()

```

The word "patient" seems to be important, but we observe a lot of stop words.

#Question 3
Redo visualization but remove stopwords before
Bonus points if you remove numbers as well
What do we see know that we have removed stop words? Does it give us a better idea of what the text is about?

```{r}
mtsamples %>%
  unnest_tokens(output = word, input = transcription) %>%
  count(word, sort = TRUE) %>%
  anti_join(stop_words, by = "word") %>%
  #using regular expressions to remove numbers
  filter(!grepl("^[0-9]+$", x = word)) %>% #"grepl" tells logical vector, "^" is the beginning of the word, "$" is the end of the word, "+" tells it should be repeated at least once
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(word, n))) +
  geom_col()
  
```


#Question 4
repeat question 2, but this time tokenize into bi-grams. how does the result change if you look at tri-grams?

```{r bi-grams-transcript, cache=TRUE}
library(Rcpp)
mtsamples %>%
  unnest_ngrams(output = bigram, input = transcription, n = 2) %>%
  count(bigram, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(bigram, n))) +
  geom_col()

```

```{r tri-grams-transcript, cache=TRUE}
mtsamples %>%
  unnest_ngrams(output = trigram, input = transcription, n = 3) %>%
  count(trigram, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(trigram, n))) +
  geom_col()

```

Now some phrases start to show up, e.g., "tolerated the procedure", "prepped and draped."



#Question 5
Using the results you got from questions 4. Pick a word and count the words that appears after and before it.


```{r bi-grams, cache=TRUE}
bigrams <- mtsamples %>%
  unnest_ngrams(output = bigram, input = transcription, n = 2) %>%
  separate(bigram, into = c("w1", "w2")) %>%
  filter((w1 == "history") | (w2 == "history"))
  

bigrams %>%
  filter(w1 == "history") %>%
  select(w1, w2) %>%
  count(w2, sort = TRUE)

bigrams %>%
  filter(w2 == "history") %>%
  select(w1, w2) %>%
  count(w2, sort = TRUE) 

```


Since we are looking at single words agian, it is a good idea to treat these as singe token. So let's remove the stop words and numbers. 

```{r history-wo-stop}
bigrams %>%
  filter(w1 == "history") %>% #keeping rows with history of first word
  filter(!(w2 %in% stop_words$word) & !grepl("^[0-9]+$", w2)) %>% #do not include words with stop words or numbers
  count(w2, sort = TRUE) %>%
  top_n(10) %>%
  knitr::kable() 

bigrams %>%
  filter(w2 == "history") %>% #keeping rows with history of first word
  filter(!(w1 %in% stop_words$word) & !grepl("^[0-9]+$", w1)) %>% #do not include words with stop words or numbers
  count(w1, sort = TRUE) %>%
  top_n(10) %>%
  knitr::kable() 
```


#Question 6
Which words are most used in each of the specialties. you can use group_by() and top_n() from dplyr to have the calculations be done within each specialty. Remember to remove stopwords. How about the most 5 used words?



```{r top-per-specialty}
mtsamples %>%
  unnest_tokens(word, input = transcription) %>%
  group_by(medical_specialty) %>%
  count(word, sort = TRUE) %>%
  filter(!(word %in% stop_words$word) & !grepl("^[0-9]+$", word)) %>%
  top_n(5) %>%
  arrange(medical_specialty, desc(n)) %>%
  knitr::kable()
```


#Question 7 - extra
Find your own insight in the data:

Ideas:

Interesting ngrams
See if certain words are used more in some specialties then others









#How to push the file in Terminal using command lines:
git add lab06/README*
git status
git commit -a -m "Starting with lab06"
git push

#How to remove the file on track:
git rm --cache -r lab06/README_cache


